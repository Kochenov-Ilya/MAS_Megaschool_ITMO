{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Привет!\n",
        " Перед началом выполнения кода проекта необходимо установить зависмости прописанные  в ячейке ниже"
      ],
      "metadata": {
        "id": "Z5HIfEgK0mi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-community  pydantic   tiktoken requests langchain_text_splitters  langchain_core typing"
      ],
      "metadata": {
        "id": "3wvzAPqm0kx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь необходимо будет прописать свой API"
      ],
      "metadata": {
        "id": "IMkjMl7P1H27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API = \"YOUR_API_KEY_HERE\"\n",
        "URL = \"https://openrouter.ai/api/v1\"\n",
        "giga = \"deepseek/deepseek-r1-0528:free\""
      ],
      "metadata": {
        "id": "X2pm96xn1HZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional, Dict\n",
        "from pydantic import BaseModel, Field\n",
        "import json\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "x8RWv_ZymN9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateProfile(BaseModel):\n",
        "    name: str\n",
        "    position: str\n",
        "    grade: str\n",
        "    experience: str\n",
        "\n",
        "class ExtractedProfile(BaseModel):\n",
        "    position: str\n",
        "    estimated_grade: str\n",
        "    experience_summary: str\n",
        "    confidence: int\n",
        "\n",
        "class TurnLog(BaseModel):\n",
        "    turn_id: int\n",
        "    agent_visible_message: str\n",
        "    user_message: str\n",
        "    internal_thoughts: Optional[str] = None\n",
        "\n",
        "class InterviewState(BaseModel):\n",
        "    candidate_profile: CandidateProfile\n",
        "    next_action: Optional[str] = None\n",
        "    interviewer_notes: Optional[str] = None\n",
        "    current_topic: Optional[str] = None\n",
        "    turn_id: int = 1\n",
        "    dialogue_history: List[TurnLog] = Field(default_factory=list)\n",
        "    last_user_message: Optional[str] = None\n",
        "    agent_visible_message: Optional[str] = None\n",
        "    covered_topics: List[str] = Field(default_factory=list)\n",
        "    last_topic: Optional[str] = None\n",
        "    difficulty_level: str = \"easy\"\n",
        "    stop_interview: bool = False\n",
        "    red_flag: bool = False\n",
        "    observer_evaluation: Optional[str] = None\n",
        "    observer_notes: Optional[str] = None\n",
        "    observer_instruction: Optional[str] = None\n",
        "    difficulty_adjustment: Optional[str] = None\n"
      ],
      "metadata": {
        "id": "p_pjk2ULmOCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "profile_llm  = ChatOpenAI(base_url=URL,model=giga, api_key=API, temperature=0)\n",
        "observer_llm = ChatOpenAI(base_url=URL,model=giga, api_key=API, temperature=0)\n",
        "interviewer_llm = ChatOpenAI(base_url=URL,model=giga, api_key=API, temperature=0.3)\n",
        "hiring_llm = ChatOpenAI(base_url=URL,model=giga, api_key=API, temperature=0)\n",
        "\n",
        "PROFILE_ANALYZER_PROMPT = \"\"\"\n",
        "Ты — HR-ассистент, анализирующий самопрезентацию кандидата.\n",
        "\n",
        "Отвечай ТОЛЬКО на русском языке.\n",
        "\n",
        "Задача:\n",
        "- Определи целевую позицию\n",
        "- Оцени уровень (Junior / Middle / Senior)\n",
        "- Кратко опиши опыт (1–2 предложения)\n",
        "- Оцени уверенность (0–100)\n",
        "\n",
        "Правила:\n",
        "- Используй ТОЛЬКО информацию из текста\n",
        "- Ничего не выдумывай\n",
        "- Если сомневаешься — выбирай более низкий уровень\n",
        "- Верни ТОЛЬКО валидный JSON:\n",
        "\n",
        "{\n",
        "  \"position\": \"string\",\n",
        "  \"estimated_grade\": \"string\",\n",
        "  \"experience_summary\": \"string\",\n",
        "  \"confidence\": number\n",
        "}\n",
        "\"\"\"\n",
        "OBSERVER_SYSTEM_PROMPT = \"\"\"\n",
        "Ты — старший инженер, наблюдающий за техническим интервью.\n",
        "\n",
        "Общайся ТОЛЬКО на русском языке.\n",
        "\n",
        "Ты НИКОГДА не общаешься с кандидатом.\n",
        "\n",
        "Ты ОБЯЗАН отвечать ТОЛЬКО валидным JSON.\n",
        "Никакого текста вне JSON.\n",
        "\n",
        "Формат:\n",
        "\n",
        "{\n",
        "  \"internal_thoughts\": \"string (на русском)\",\n",
        "  \"evaluation\": \"strong | ok | weak | hallucination\",\n",
        "  \"instruction\": \"ask_followup | simplify | challenge | proceed | stop | answer_candidate\"\n",
        "}\n",
        "\n",
        "Правила:\n",
        "\n",
        "- Если кандидат задал вопрос → instruction = \"answer_candidate\"\n",
        "- Если обнаружена ложь / выдумка → evaluation = \"hallucination\", instruction = \"challenge\"\n",
        "- Если ответ слабый → \"challenge\"\n",
        "- Если хороший → \"proceed\"\n",
        "- Если диалог зашёл в тупик → \"stop\"\n",
        "\"\"\"\n",
        "\n",
        "INTERVIEWER_SYSTEM_PROMPT = \"\"\"\n",
        "Ты — технический интервьюер.\n",
        "\n",
        "Ты общаешься с кандидатом ТОЛЬКО на русском языке.\n",
        "\n",
        "Правила:\n",
        "- Задавай ОДИН вопрос за раз\n",
        "- Будь вежливым и профессиональным\n",
        "- Никогда явно не оценивай кандидата\n",
        "- Следуй инструкциям наблюдателя\n",
        "- Не используй английский язык\n",
        "\"\"\"\n",
        "HIRING_MANAGER_PROMPT = \"\"\"\n",
        "Ты — опытный hiring manager.\n",
        "\n",
        "Ты анализируешь техническое интервью.\n",
        "\n",
        "Отвечай ТОЛЬКО на русском языке.\n",
        "Верни ТОЛЬКО валидный JSON.\n",
        "\n",
        "Твоя задача — дать ЧЕСТНУЮ и ДЕТАЛЬНУЮ оценку.\n",
        "\n",
        "Обязательно:\n",
        "\n",
        "1. Используй оценки observer (evaluation).\n",
        "2. Учитывай случаи hallucination и ухода от темы.\n",
        "3. Не оставляй разделы пустыми.\n",
        "4. Делай выводы на основе диалога.\n",
        "\n",
        "Если кандидат:\n",
        "- даёт ложную информацию → снижай оценку\n",
        "- уходит от вопросов → снижать soft skills\n",
        "- даёт хорошие ответы → фиксировать как skill\n",
        "\n",
        "Формат:\n",
        "\n",
        "{\n",
        "  \"decision\": {\n",
        "    \"grade\": \"Junior | Middle | Senior\",\n",
        "    \"hiring_recommendation\": \"Hire | No Hire | Strong Hire\",\n",
        "    \"confidence_score\": number\n",
        "  },\n",
        "\n",
        "  \"hard_skills\": {\n",
        "    \"confirmed_skills\": [\n",
        "      {\n",
        "        \"topic\": \"string\",\n",
        "        \"evidence\": \"string\"\n",
        "      }\n",
        "    ],\n",
        "\n",
        "    \"knowledge_gaps\": [\n",
        "      {\n",
        "        \"topic\": \"string\",\n",
        "        \"candidate_answer\": \"string\",\n",
        "        \"correct_answer\": \"string\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "\n",
        "  \"soft_skills\": {\n",
        "    \"clarity\": \"low | medium | high\",\n",
        "    \"honesty\": \"low | medium | high\",\n",
        "    \"engagement\": \"low | medium | high\"\n",
        "  },\n",
        "\n",
        "  \"roadmap\": [\n",
        "    \"string\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "Никакого markdown.\n",
        "Никаких пояснений.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "hdl9css30rHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROFILE_SCHEMA = {\n",
        "    \"position\": str,             # позиция или роль (Analyst, Developer, CTO)\n",
        "    \"estimated_grade\": str,      # любая строка (Junior, Senior, CTO, Intern)\n",
        "    \"experience_summary\": str,   # текстовое описание опыта\n",
        "    \"confidence\": int            # 0-100\n",
        "}"
      ],
      "metadata": {
        "id": "lcSjtLiYtywV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_profile_output(data: dict) -> dict:\n",
        "    normalized = {}\n",
        "\n",
        "    # 1. позиция\n",
        "    for key in [\"position\", \"target_position\", \"role\", \"desired_position\"]:\n",
        "        if key in data:\n",
        "            normalized[\"position\"] = data[key]\n",
        "            break\n",
        "    else:\n",
        "        normalized[\"position\"] = \"Unknown\"\n",
        "\n",
        "    # 2. грейд\n",
        "    grade = data.get(\"estimated_grade\") or data.get(\"grade\") or data.get(\"seniority\") or \"Unknown\"\n",
        "    normalized[\"estimated_grade\"] = str(grade)\n",
        "\n",
        "    # 3. опыт\n",
        "    normalized[\"experience_summary\"] = data.get(\n",
        "        \"experience_summary\"\n",
        "    ) or data.get(\"experience\") or data.get(\"background\") or \"Not provided\"\n",
        "\n",
        "    # 4. confidence\n",
        "    conf = data.get(\"confidence\", 50)\n",
        "    if isinstance(conf, dict):\n",
        "        conf = min(conf.values())\n",
        "    elif isinstance(conf, list):\n",
        "        conf = min(conf)\n",
        "    elif not isinstance(conf, int):\n",
        "        conf = 50\n",
        "\n",
        "    normalized[\"confidence\"] = max(0, min(100, int(conf)))\n",
        "\n",
        "    return normalized"
      ],
      "metadata": {
        "id": "VDPoAV4etwKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_profile(data: dict) -> bool:\n",
        "    return all(\n",
        "        k in data and (data[k] is not None) and (data[k] != \"\")\n",
        "        for k in PROFILE_SCHEMA\n",
        "    )"
      ],
      "metadata": {
        "id": "PLGdBBkotwPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_candidate_profile(intro_text: str, llm) -> ExtractedProfile:\n",
        "    \"\"\"\n",
        "    Извлекает профиль кандидата из вступительного текста\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = llm.invoke([\n",
        "            SystemMessage(content=PROFILE_ANALYZER_PROMPT),\n",
        "            HumanMessage(content=intro_text)\n",
        "        ])\n",
        "\n",
        "        # Убираем возможные markdown блоки и пробелы\n",
        "        raw = response.content.strip()\n",
        "        raw = re.sub(r\"```json|```\", \"\", raw).strip()\n",
        "\n",
        "        if not raw:\n",
        "            raise ValueError(\"Empty response from LLM\")\n",
        "\n",
        "        parsed = json.loads(raw)\n",
        "        normalized = normalize_profile_output(parsed)\n",
        "\n",
        "        if not validate_profile(normalized):\n",
        "            raise ValueError(\"Profile validation failed\")\n",
        "\n",
        "        return ExtractedProfile(**normalized)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"[ProfileAnalyzer ERROR] JSON parsing failed: {e}\")\n",
        "        print(f\"Raw output: {raw if 'raw' in locals() else 'No response'}\")\n",
        "\n",
        "        # Fallback: попробуем извлечь данные через регулярные выражения\n",
        "        return extract_profile_fallback(intro_text)\n",
        "    except Exception as e:\n",
        "        print(f\"[ProfileAnalyzer ERROR] Unexpected error: {e}\")\n",
        "        return ExtractedProfile(\n",
        "            position=\"Unknown\",\n",
        "            estimated_grade=\"Junior\",  # Безопасный выбор\n",
        "            experience_summary=\"Insufficient data provided by candidate.\",\n",
        "            confidence=30\n",
        "        )"
      ],
      "metadata": {
        "id": "QKg45G1ZnsUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_profile_fallback(intro_text: str) -> ExtractedProfile:\n",
        "    \"\"\"\n",
        "    Fallback метод для извлечения профиля при ошибках LLM\n",
        "    \"\"\"\n",
        "    position = \"Unknown\"\n",
        "    grade = \"Junior\"\n",
        "    experience = intro_text[:200] + \"...\" if len(intro_text) > 200 else intro_text\n",
        "\n",
        "    # Простая эвристика для определения позиции\n",
        "    keywords = {\n",
        "        \"developer\": \"Software Developer\",\n",
        "        \"engineer\": \"Software Engineer\",\n",
        "        \"analyst\": \"Data Analyst\",\n",
        "        \"scientist\": \"Data Scientist\",\n",
        "        \"manager\": \"Project Manager\",\n",
        "        \"designer\": \"UX Designer\"\n",
        "    }\n",
        "\n",
        "    intro_lower = intro_text.lower()\n",
        "    for key, value in keywords.items():\n",
        "        if key in intro_lower:\n",
        "            position = value\n",
        "            break\n",
        "\n",
        "    # Эвристика для определения грейда\n",
        "    if \"senior\" in intro_lower:\n",
        "        grade = \"Senior\"\n",
        "    elif \"junior\" in intro_lower:\n",
        "        grade = \"Junior\"\n",
        "    elif \"mid\" in intro_lower or \"middle\" in intro_lower:\n",
        "        grade = \"Middle\"\n",
        "\n",
        "    return ExtractedProfile(\n",
        "        position=position,\n",
        "        estimated_grade=grade,\n",
        "        experience_summary=experience,\n",
        "        confidence=40\n",
        "    )"
      ],
      "metadata": {
        "id": "xIv5mYqvn6wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def observer_agent(state: InterviewState) -> InterviewState:\n",
        "\n",
        "    if not state.last_user_message:\n",
        "        return state\n",
        "\n",
        "\n",
        "    # ===== PROMPT =====\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Ты — аналитический модуль интервью.\n",
        "\n",
        "Контекст:\n",
        "\n",
        "Профиль кандидата:\n",
        "Позиция: {state.candidate_profile.position}\n",
        "Уровень: {state.candidate_profile.grade}\n",
        "Опыт: {state.candidate_profile.experience}\n",
        "\n",
        "Последний вопрос интервьюера:\n",
        "\"{state.agent_visible_message}\"\n",
        "\n",
        "Ответ кандидата:\n",
        "\"{state.last_user_message}\"\n",
        "\n",
        "Сложность: {state.difficulty_level}\n",
        "\n",
        "Задача:\n",
        "\n",
        "Проанализируй сообщение кандидата.\n",
        "\n",
        "Определи:\n",
        "\n",
        "1. Является ли сообщение вопросом к интервьюеру.\n",
        "2. Соответствует ли ответ заданному вопросу.\n",
        "3. Есть ли выдумка, дезинформация или уход от темы.\n",
        "\n",
        "Верни JSON строго в следующем формате:\n",
        "\n",
        "{{\n",
        "  \"is_question\": true | false,\n",
        "  \"evaluation\": \"strong\" | \"ok\" | \"weak\" | \"hallucination\",\n",
        "  \"instruction\": \"answer_candidate\" | \"challenge\" | \"proceed\" | \"stop\",\n",
        "  \"internal_thoughts\": \"краткое описание оценки\"\n",
        "}}\n",
        "\n",
        "Правила:\n",
        "\n",
        "- Если кандидат задал вопрос → is_question = true и instruction = \"answer_candidate\"\n",
        "- Если есть выдумка → evaluation = \"hallucination\" и instruction = \"challenge\"\n",
        "- Если ответ не по теме → evaluation = \"weak\" и instruction = \"challenge\"\n",
        "- Если ответ корректный → evaluation = \"ok\" и instruction = \"proceed\"\n",
        "- Никакого текста вне JSON\n",
        "\"\"\"\n",
        "\n",
        "    # ===== LLM CALL =====\n",
        "\n",
        "    try:\n",
        "\n",
        "        response = observer_llm.invoke([\n",
        "            SystemMessage(content=OBSERVER_SYSTEM_PROMPT),\n",
        "            HumanMessage(content=prompt)\n",
        "        ])\n",
        "\n",
        "        raw = (response.content or \"\").strip()\n",
        "\n",
        "        raw = re.sub(r\"```json|```\", \"\", raw).strip()\n",
        "\n",
        "        match = re.search(r\"\\{.*\\}\", raw, re.S)\n",
        "\n",
        "        if not match:\n",
        "            raise ValueError(\"No JSON found\")\n",
        "\n",
        "        result = json.loads(match.group(0))\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        # Fallback если LLM сломался\n",
        "\n",
        "        result = {\n",
        "            \"is_question\": False,\n",
        "            \"evaluation\": \"weak\",\n",
        "            \"instruction\": \"proceed\",\n",
        "            \"internal_thoughts\": \"Fallback: ошибка анализа observer\"\n",
        "        }\n",
        "\n",
        "    # ===== VALIDATION =====\n",
        "\n",
        "    is_question = result.get(\"is_question\", False)\n",
        "\n",
        "    if not isinstance(is_question, bool):\n",
        "        is_question = False\n",
        "\n",
        "    evaluation = result.get(\"evaluation\", \"ok\")\n",
        "\n",
        "    if evaluation not in {\"strong\", \"ok\", \"weak\", \"hallucination\"}:\n",
        "        evaluation = \"ok\"\n",
        "\n",
        "    instruction = result.get(\"instruction\", \"proceed\")\n",
        "\n",
        "    allowed = {\n",
        "        \"answer_candidate\",\n",
        "        \"challenge\",\n",
        "        \"proceed\",\n",
        "        \"stop\"\n",
        "    }\n",
        "\n",
        "    if instruction not in allowed:\n",
        "        instruction = \"proceed\"\n",
        "\n",
        "    internal_thoughts = result.get(\n",
        "        \"internal_thoughts\",\n",
        "        \"Нет комментариев\"\n",
        "    )\n",
        "\n",
        "    # ===== BUSINESS LOGIC =====\n",
        "\n",
        "    # Вопрос кандидата всегда в приоритете\n",
        "    if is_question:\n",
        "        instruction = \"answer_candidate\"\n",
        "\n",
        "    # Галлюцинация = красный флаг\n",
        "    if evaluation == \"hallucination\":\n",
        "        state.red_flag = True\n",
        "        state.difficulty_adjustment = \"down\"\n",
        "\n",
        "    elif instruction == \"challenge\":\n",
        "        state.difficulty_adjustment = \"up\"\n",
        "\n",
        "\n",
        "    elif instruction == \"proceed\":\n",
        "        state.difficulty_adjustment = None\n",
        "\n",
        "    # ===== LOGGING =====\n",
        "\n",
        "    state.observer_notes = f\"{internal_thoughts} | {evaluation}\"\n",
        "    state.next_action = instruction\n",
        "    state.observer_instruction = instruction\n",
        "    state.observer_evaluation = evaluation\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "zEDGekAQmORZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interviewer_agent(state: InterviewState) -> InterviewState:\n",
        "\n",
        "\n",
        "    # ===== ОТВЕТ НА ВОПРОС КАНДИДАТА =====\n",
        "    if state.next_action == \"answer_candidate\":\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Кандидат задал вопрос:\n",
        "\n",
        "\"{state.last_user_message}\"\n",
        "\n",
        "Ответь кратко и профессионально.\n",
        "Затем верни разговор к техническому интервью.\n",
        "\"\"\"\n",
        "\n",
        "        response = interviewer_llm.invoke([\n",
        "            SystemMessage(content=INTERVIEWER_SYSTEM_PROMPT),\n",
        "            HumanMessage(content=prompt)\n",
        "        ])\n",
        "\n",
        "        state.agent_visible_message = response.content.strip()\n",
        "\n",
        "        # Мысли интервьюера\n",
        "        state.interviewer_notes = (\n",
        "            \"Ответил на вопрос кандидата и вернул фокус на интервью.\"\n",
        "        )\n",
        "\n",
        "        state.next_action = \"proceed\"\n",
        "\n",
        "        return state\n",
        "\n",
        "\n",
        "    # ===== РЕАКЦИЯ НА ГАЛЛЮЦИНАЦИИ =====\n",
        "    if state.red_flag:\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Кандидат дал ложную или вымышленную информацию:\n",
        "\n",
        "\"{state.last_user_message}\"\n",
        "\n",
        "Вежливо укажи на ошибку.\n",
        "Попроси объяснить корректно.\n",
        "\"\"\"\n",
        "\n",
        "        response = interviewer_llm.invoke([\n",
        "            SystemMessage(content=INTERVIEWER_SYSTEM_PROMPT),\n",
        "            HumanMessage(content=prompt)\n",
        "        ])\n",
        "\n",
        "        state.agent_visible_message = response.content.strip()\n",
        "\n",
        "        state.interviewer_notes = (\n",
        "            \"Обнаружена возможная галлюцинация — запросил уточнение.\"\n",
        "        )\n",
        "\n",
        "        state.red_flag = False\n",
        "\n",
        "        return state\n",
        "\n",
        "\n",
        "    # ===== УПРАВЛЕНИЕ СЛОЖНОСТЬЮ =====\n",
        "    if state.difficulty_adjustment == \"up\":\n",
        "        state.difficulty_level = \"hard\"\n",
        "        diff_note = \"Усложнил следующий вопрос.\"\n",
        "\n",
        "    elif state.difficulty_adjustment == \"down\":\n",
        "        state.difficulty_level = \"easy\"\n",
        "        diff_note = \"Упростил следующий вопрос.\"\n",
        "\n",
        "    else:\n",
        "        diff_note = \"Сохранил текущий уровень сложности.\"\n",
        "\n",
        "\n",
        "    # ===== ОСНОВНОЙ ВОПРОС =====\n",
        "    prompt = f\"\"\"\n",
        "Контекст интервью:\n",
        "\n",
        "Позиция: {state.candidate_profile.position}\n",
        "Уровень: {state.candidate_profile.grade}\n",
        "Опыт: {state.candidate_profile.experience}\n",
        "Сложность: {state.difficulty_level}\n",
        "\n",
        "Пройденные темы: {state.covered_topics}\n",
        "\n",
        "Последний вопрос: {state.agent_visible_message}\n",
        "Последний ответ: {state.last_user_message}\n",
        "\n",
        "Инструкция:\n",
        "{state.next_action}\n",
        "\n",
        "Задай следующий технический вопрос.\n",
        "\n",
        "Правила:\n",
        "- Один вопрос\n",
        "- Без английского\n",
        "- Не повторяйся\n",
        "\"\"\"\n",
        "\n",
        "    response = interviewer_llm.invoke([\n",
        "        SystemMessage(content=INTERVIEWER_SYSTEM_PROMPT),\n",
        "        HumanMessage(content=prompt)\n",
        "    ])\n",
        "\n",
        "    message = response.content.strip()\n",
        "\n",
        "    if not message:\n",
        "        message = \"Поясните, пожалуйста, свой ответ подробнее.\"\n",
        "\n",
        "    state.agent_visible_message = message\n",
        "\n",
        "\n",
        "    # Мысли интервьюера\n",
        "    state.interviewer_notes = (\n",
        "        f\"Сформировал следующий вопрос. {diff_note}\"\n",
        "    )\n",
        "\n",
        "\n",
        "    if state.next_action == \"stop\":\n",
        "        state.stop_interview = True\n",
        "        return state\n",
        "\n",
        "\n",
        "    state.current_topic = message\n",
        "    state.covered_topics.append(message)\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "QJxcctjqmOTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_turn(state: InterviewState) -> InterviewState:\n",
        "\n",
        "    thoughts = \"\"\n",
        "\n",
        "    if state.observer_notes:\n",
        "        thoughts += f\"[Observer]: {state.observer_notes}\\n\"\n",
        "\n",
        "    if state.interviewer_notes:\n",
        "        thoughts += f\"[Interviewer]: {state.interviewer_notes}\\n\"\n",
        "\n",
        "\n",
        "    state.dialogue_history.append(\n",
        "        TurnLog(\n",
        "            turn_id=state.turn_id,\n",
        "            agent_visible_message=state.agent_visible_message or \"\",\n",
        "            user_message=state.last_user_message or \"\",\n",
        "            internal_thoughts=thoughts.strip()\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Сброс после записи\n",
        "    state.observer_notes = None\n",
        "    state.interviewer_notes = None\n",
        "\n",
        "    state.turn_id += 1\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "IALUvcT3mOWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(state: InterviewState) -> dict:\n",
        "    \"\"\"\n",
        "    Generates final interview feedback using Hiring Manager LLM\n",
        "    with observer-based scoring and intelligent fallback\n",
        "    with fully dynamic roadmap\n",
        "    \"\"\"\n",
        "\n",
        "    conversation = []\n",
        "\n",
        "    # ===== Сбор истории =====\n",
        "    for turn in state.dialogue_history:\n",
        "\n",
        "        eval_tag = \"unknown\"\n",
        "\n",
        "        if turn.internal_thoughts:\n",
        "            text = turn.internal_thoughts.lower()\n",
        "\n",
        "            if \"hallucination\" in text:\n",
        "                eval_tag = \"hallucination\"\n",
        "            elif \"strong\" in text:\n",
        "                eval_tag = \"strong\"\n",
        "            elif \"weak\" in text:\n",
        "                eval_tag = \"weak\"\n",
        "            elif \"ok\" in text:\n",
        "                eval_tag = \"ok\"\n",
        "\n",
        "        conversation.append({\n",
        "            \"turn_id\": turn.turn_id,\n",
        "            \"question\": turn.agent_visible_message,\n",
        "            \"answer\": turn.user_message,\n",
        "            \"evaluation\": eval_tag,\n",
        "            \"observer_notes\": turn.internal_thoughts\n",
        "        })\n",
        "\n",
        "\n",
        "    # ===== Статистика =====\n",
        "    stats = {\n",
        "        \"strong\": 0,\n",
        "        \"ok\": 0,\n",
        "        \"weak\": 0,\n",
        "        \"hallucination\": 0,\n",
        "        \"unknown\": 0\n",
        "    }\n",
        "\n",
        "    for turn in conversation:\n",
        "        tag = turn.get(\"evaluation\", \"unknown\")\n",
        "        stats[tag] = stats.get(tag, 0) + 1\n",
        "\n",
        "\n",
        "    # ===== PROMPT =====\n",
        "    prompt = f\"\"\"\n",
        "Ты — опытный hiring manager.\n",
        "\n",
        "Тебе передана полная история интервью и оценки observer.\n",
        "\n",
        "Профиль кандидата:\n",
        "Имя: {state.candidate_profile.name}\n",
        "Позиция: {state.candidate_profile.position}\n",
        "Уровень: {state.candidate_profile.grade}\n",
        "Опыт: {state.candidate_profile.experience}\n",
        "\n",
        "Статистика ответов:\n",
        "{json.dumps(stats, ensure_ascii=False, indent=2)}\n",
        "\n",
        "История интервью:\n",
        "{json.dumps(conversation, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Твоя задача:\n",
        "\n",
        "1. Оцени кандидата честно.\n",
        "2. Выяви реальные сильные и слабые стороны.\n",
        "3. Сформируй персональный план развития (roadmap),\n",
        "   основанный ТОЛЬКО на этом интервью.\n",
        "\n",
        "Roadmap должен:\n",
        "- Быть конкретным\n",
        "- Отражать пробелы знаний\n",
        "- Не быть шаблонным\n",
        "- Быть связан с ошибками кандидата\n",
        "\n",
        "Обязательно заполни ВСЕ разделы.\n",
        "\n",
        "Верни ТОЛЬКО валидный JSON строго по формату.\n",
        "\n",
        "Никаких пояснений.\n",
        "Никакого markdown.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # ===== LLM CALL =====\n",
        "    try:\n",
        "\n",
        "        response = hiring_llm.invoke([\n",
        "            SystemMessage(content=HIRING_MANAGER_PROMPT),\n",
        "            HumanMessage(content=prompt)\n",
        "        ])\n",
        "\n",
        "        raw = (response.content or \"\").strip()\n",
        "\n",
        "        raw = re.sub(r\"```json|```\", \"\", raw).strip()\n",
        "\n",
        "        if not raw:\n",
        "            raise ValueError(\"Empty LLM response\")\n",
        "\n",
        "        parsed = json.loads(raw)\n",
        "\n",
        "        # Валидация roadmap\n",
        "        if \"roadmap\" not in parsed or not parsed[\"roadmap\"]:\n",
        "            raise ValueError(\"Missing roadmap\")\n",
        "\n",
        "        if not isinstance(parsed[\"roadmap\"], list):\n",
        "            raise ValueError(\"Invalid roadmap format\")\n",
        "\n",
        "        return parsed\n",
        "\n",
        "\n",
        "    # ===== INTELLIGENT FALLBACK =====\n",
        "    except Exception:\n",
        "\n",
        "        # Анализ слабых мест из диалога\n",
        "        weak_topics = []\n",
        "\n",
        "        for turn in conversation:\n",
        "\n",
        "            if turn[\"evaluation\"] in {\"weak\", \"hallucination\"}:\n",
        "\n",
        "                q = turn[\"question\"][:80]\n",
        "\n",
        "                weak_topics.append(q)\n",
        "\n",
        "\n",
        "        # Уникальные\n",
        "        weak_topics = list(set(weak_topics))\n",
        "\n",
        "\n",
        "        roadmap = []\n",
        "\n",
        "\n",
        "        for topic in weak_topics:\n",
        "\n",
        "            roadmap.append(\n",
        "                f\"Повторить и отработать тему: «{topic}»\"\n",
        "            )\n",
        "\n",
        "\n",
        "        # Если совсем пусто — общий план\n",
        "        if not roadmap:\n",
        "\n",
        "            roadmap = [\n",
        "                \"Углубить знание базовых конструкций Python\",\n",
        "                \"Практиковаться в объяснении алгоритмов\",\n",
        "                \"Улучшить навыки анализа задач\",\n",
        "                \"Решать задачи уровня своего грейда\"\n",
        "            ]\n",
        "\n",
        "\n",
        "        # Оценка confidence\n",
        "        hallucinations = stats.get(\"hallucination\", 0)\n",
        "        weak = stats.get(\"weak\", 0)\n",
        "        strong = stats.get(\"strong\", 0)\n",
        "\n",
        "        confidence = 60\n",
        "        confidence -= hallucinations * 15\n",
        "        confidence -= weak * 5\n",
        "        confidence += strong * 5\n",
        "\n",
        "        confidence = max(20, min(90, confidence))\n",
        "\n",
        "\n",
        "        # Recommendation\n",
        "        if hallucinations > 0 or weak >= 3:\n",
        "            recommendation = \"No Hire\"\n",
        "        elif strong >= 3:\n",
        "            recommendation = \"Strong Hire\"\n",
        "        else:\n",
        "            recommendation = \"Hire\"\n",
        "\n",
        "\n",
        "        # Soft skills\n",
        "        clarity = \"medium\"\n",
        "        honesty = \"medium\"\n",
        "        engagement = \"medium\"\n",
        "\n",
        "        if weak >= 2:\n",
        "            clarity = \"low\"\n",
        "\n",
        "        if hallucinations > 0:\n",
        "            honesty = \"low\"\n",
        "\n",
        "        if stats.get(\"unknown\", 0) > 2:\n",
        "            engagement = \"low\"\n",
        "\n",
        "\n",
        "        return {\n",
        "            \"decision\": {\n",
        "                \"grade\": state.candidate_profile.grade,\n",
        "                \"hiring_recommendation\": recommendation,\n",
        "                \"confidence_score\": confidence\n",
        "            },\n",
        "\n",
        "            \"hard_skills\": {\n",
        "                \"confirmed_skills\": [],\n",
        "                \"knowledge_gaps\": []\n",
        "            },\n",
        "\n",
        "            \"soft_skills\": {\n",
        "                \"clarity\": clarity,\n",
        "                \"honesty\": honesty,\n",
        "                \"engagement\": engagement\n",
        "            },\n",
        "\n",
        "            \"roadmap\": roadmap\n",
        "        }"
      ],
      "metadata": {
        "id": "mMOP8LsYLWyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_feedback(feedback_json: dict) -> str:\n",
        "    \"\"\"\n",
        "    Converts feedback JSON to readable text format\n",
        "    \"\"\"\n",
        "\n",
        "    decision = feedback_json.get(\"decision\", {})\n",
        "    hard = feedback_json.get(\"hard_skills\", {})\n",
        "    soft = feedback_json.get(\"soft_skills\", {})\n",
        "    roadmap = feedback_json.get(\"roadmap\", [])\n",
        "\n",
        "    text = []\n",
        "\n",
        "    # Вердикт\n",
        "    text.append(\"=== Вердикт ===\")\n",
        "    text.append(f\"Grade: {decision.get('grade')}\")\n",
        "    text.append(f\"Recommendation: {decision.get('hiring_recommendation')}\")\n",
        "    text.append(f\"Confidence: {decision.get('confidence_score')}%\")\n",
        "\n",
        "    # Hard skills\n",
        "    text.append(\"\\n=== Анализ Hard Skills ===\")\n",
        "\n",
        "    text.append(\"\\nПодтверждённые навыки:\")\n",
        "    for s in hard.get(\"confirmed_skills\", []):\n",
        "        text.append(f\"- {s.get('topic')}: {s.get('evidence')}\")\n",
        "\n",
        "    text.append(\"\\nПробелы в знаниях:\")\n",
        "    for g in hard.get(\"knowledge_gaps\", []):\n",
        "        text.append(f\"- {g.get('topic')}\")\n",
        "        text.append(f\"  Ответ: {g.get('candidate_answer')}\")\n",
        "        text.append(f\"  Правильно: {g.get('correct_answer')}\")\n",
        "\n",
        "    # Soft skills\n",
        "    text.append(\"\\n=== Soft Skills ===\")\n",
        "    text.append(f\"Clarity: {soft.get('clarity')}\")\n",
        "    text.append(f\"Honesty: {soft.get('honesty')}\")\n",
        "    text.append(f\"Engagement: {soft.get('engagement')}\")\n",
        "\n",
        "    # Roadmap\n",
        "    text.append(\"\\n=== Roadmap ===\")\n",
        "\n",
        "    for r in roadmap:\n",
        "        text.append(f\"- {r}\")\n",
        "\n",
        "    return \"\\n\".join(text)"
      ],
      "metadata": {
        "id": "EYotqPI1XW5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # ===== ВВОД ФИО =====\n",
        "    participant_name = input(\"Введите ваше ФИО: \").strip()\n",
        "\n",
        "    if not participant_name:\n",
        "        participant_name = \"Не указано\"\n",
        "\n",
        "    print(\"\\nРасскажи о себе: опыт, технологии, на какую позицию метишь.\")\n",
        "    intro = input(\"Candidate: \")\n",
        "\n",
        "    # ===== АНАЛИЗ ПРОФИЛЯ =====\n",
        "    profile = extract_candidate_profile(intro, profile_llm)\n",
        "\n",
        "    state = InterviewState(\n",
        "        candidate_profile=CandidateProfile(\n",
        "            name=participant_name,   # ← сохраняем ФИО\n",
        "            position=profile.position,\n",
        "            grade=profile.estimated_grade,\n",
        "            experience=profile.experience_summary\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # ===== НАСТРОЙКА СЛОЖНОСТИ =====\n",
        "    GRADE_TO_DIFFICULTY = {\n",
        "        \"Junior\": \"easy\",\n",
        "        \"Middle\": \"medium\",\n",
        "        \"Senior\": \"hard\"\n",
        "    }\n",
        "\n",
        "    state.difficulty_level = GRADE_TO_DIFFICULTY.get(\n",
        "        profile.estimated_grade,\n",
        "        \"easy\"\n",
        "    )\n",
        "\n",
        "    state.next_action = \"ask_new\"\n",
        "\n",
        "    # ===== ПЕРВЫЙ ВОПРОС =====\n",
        "    state = interviewer_agent(state)\n",
        "\n",
        "    print(\"\\nInterviewer:\", state.agent_visible_message)\n",
        "\n",
        "    max_turns = 11\n",
        "    turn_count = 1\n",
        "\n",
        "    # ===== ОСНОВНОЙ ЦИКЛ =====\n",
        "    while not state.stop_interview and turn_count < max_turns:\n",
        "\n",
        "        # ВВОД ОТ КАНДИДАТА\n",
        "        user_input = input(\"\\nCandidate: \").strip()\n",
        "\n",
        "        if user_input.lower().startswith(\"стоп\"):\n",
        "            state.stop_interview = True\n",
        "            break\n",
        "\n",
        "        state.last_user_message = user_input\n",
        "\n",
        "        # ОБРАБОТКА АГЕНТАМИ\n",
        "        state = observer_agent(state)\n",
        "        state = interviewer_agent(state)\n",
        "        state = log_turn(state)\n",
        "\n",
        "        # ВЫВОД\n",
        "        print(\"\\nInterviewer:\", state.agent_visible_message)\n",
        "\n",
        "        turn_count += 1\n",
        "\n",
        "    print(\"\\n=== Interview finished ===\")\n",
        "\n",
        "    # ===== ФИДБЭК =====\n",
        "    feedback = generate_feedback(state)\n",
        "\n",
        "    formatted_feedback = format_feedback(feedback)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"FINAL FEEDBACK:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(formatted_feedback)\n",
        "\n",
        "    # ===== СОХРАНЕНИЕ ЛОГА =====\n",
        "\n",
        "    filename = f\"interview_log_{participant_name.replace(' ', '_')}.json\"\n",
        "\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "\n",
        "        json.dump(\n",
        "            {\n",
        "                \"participant_name\": state.candidate_profile.name,\n",
        "\n",
        "                \"turns\": [\n",
        "                    {\n",
        "                        \"turn_id\": t.turn_id,\n",
        "                        \"agent_visible_message\": t.agent_visible_message,\n",
        "                        \"user_message\": t.user_message,\n",
        "                        \"internal_thoughts\": t.internal_thoughts\n",
        "                    }\n",
        "                    for t in state.dialogue_history\n",
        "                ],\n",
        "\n",
        "                # В ТЗ — строка, не объект\n",
        "                \"final_feedback\": formatted_feedback\n",
        "            },\n",
        "            f,\n",
        "            ensure_ascii=False,\n",
        "            indent=2\n",
        "        )\n",
        "\n",
        "    print(f\"\\nЛог сохранён в файл: {filename}\")"
      ],
      "metadata": {
        "id": "r2yU1-gCG4Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "rJNA181D_Oze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547508ba-ebc1-465a-f0dd-36158df83135"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите ваше ФИО: Коченов Илья Сергеевич\n",
            "\n",
            "Расскажи о себе: опыт, технологии, на какую позицию метишь.\n",
            "Candidate: ривет, я Иван. Я ручной тестировщик. Сразу предупреждаю: программировать я не умею, автоматизацию не знаю.\n",
            "\n",
            "Interviewer: Отлично, давайте начнём. Мой первый вопрос:  \n",
            "\n",
            "**Что такое тест-кейс и перечислите основные элементы, которые обычно в него входят?**\n",
            "\n",
            "Candidate: Тест-кейс — это документ, в котором описан конкретный сценарий проверки работы определённой функции или части системы. Он нужен для того, чтобы тестировщик понимал, что именно и как нужно проверить. Основная цель тест-кейса — убедиться, что программа работает в соответствии с требованиями. Каждый тест-кейс должен быть понятным, однозначным и воспроизводимым.  В первую очередь в тест-кейсе указывается его уникальный идентификатор, чтобы его можно было легко найти в системе тестирования. Далее обычно прописывается название или краткое описание проверки. Важным элементом являются предусловия — условия, которые должны быть выполнены перед началом тестирования. Также обязательно указываются шаги теста, то есть последовательность действий, которые должен выполнить тестировщик.  Ещё одним ключевым элементом являются входные данные, если они используются в проверке. После этого описывается ожидаемый результат — то, что должно произойти при корректной работе системы. Иногда в тест-кейсе указывают фактический результат после выполнения проверки. Также может присутствовать поле со статусом теста, например Passed, Failed или Blocked.  Дополнительно в тест-кейсе могут быть указаны приоритет, серьёзность или ссылка на требование. В некоторых случаях добавляют комментарии или примечания для других тестировщиков. Все эти элементы помогают сделать процесс тестирования более структурированным и понятным.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "scjclA2k3bEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}